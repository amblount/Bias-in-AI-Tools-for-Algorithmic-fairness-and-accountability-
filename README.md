#The Authors 
[Alivia Blount](https://www.linkedin.com/in/aliviablount/)
[Camille Eddy](https://www.linkedin.com/in/camilleeddy/)

# Bias in AI Tools for Algorithmic fairness and accountability
[Explanation of Talk](https://www.youtube.com/watch?v=LFADNppMYZQ)

## Abstract
Abstract:

In an effort to combat bias we need systems that provide transparency in algorithms. These systems would provide information on what an algorithm decided and why it made its decision. Including the obvious missteps of cultural biases to the biases that are more subtle. This workshop will go over the first steps you can take with new open source tools from IBM and Google called AI Fairness 360 and What-If respectively. We will also briefly point out steps and features that Microsoft and Amazon announced for their upcoming AI transparency tools.  

#### [Microsoft](https://www.microsoft.com/en-us/research/blog/machine-learning-for-fair-decisions/)

#### [Google](https://ai.googleblog.com/2018/09/the-what-if-tool-code-free-probing-of.html)

#### [IBM](https://www.ibm.com/blogs/research/2018/09/ai-fairness-360/)

## Background Reading

- [AI Fairness 360: An extensible toolkit for detecting understanding, and mitigating unwanted bias](https://arxiv.org/pdf/1810.01943.pdf)

- [A reductions approach to fair classification](https://arxiv.org/pdf/1803.02453.pdf)

- [Improving fairness in machine learning systems, what do industry practitioners need?](https://arxiv.org/pdf/1812.05239.pdf)

- [Assessing and addressing algorithmic bias in practice](http://interactions.acm.org/archive/view/november-december-2018/assessing-and-addressing-algorithmic-bias-in-practice)

- [Intro to data ethics](https://www.scu.edu/media/ethics-center/technology-ethics/IntroToDataEthics.pdf)

- [Framework for ethical decision making](https://www.scu.edu/ethics/ethics-resources/ethical-decision-making/a-framework-for-ethical-decision-making/)

- [Types of bias](https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias)

- [Trouble with AI Bias](https://www.technologyreview.com/s/612876/this-is-how-ai-bias-really-happensand-why-its-so-hard-to-fix/)

- [Algorithm accountability act](https://www.booker.senate.gov/?p=press_release&id=903)

- [Case Study facial recognition]([https://www.scu.edu/ethics-in-technology-practice/case-studies/facial-recognition-technology/)

- [AI Fairness 360 toolkit](https://aif360.mybluemix.net/)


## Datasets

[Kaggle](https://www.kaggle.com/datasets?sortBy=hottest&group=public&page=1&pageSize=20&size=all&filetype=all&license=all&maintainerOrgId=4)

## Product Examples

1. [Microsoft AI Bot - Tay]()

2. [Norman]()

3. [Contextual Lineup - Facial Recognition Database]()

  - People are unknowingly added to the system

4. [Dreamers - ICE Raids](https://www.politico.com/story/2017/09/05/dreamers-fear-deportation-immigrants-242351)

5. [Autonomous fleets - pickups](https://uberpeople.net/threads/uber-dispatch-algorithm%E2%80%94we%E2%80%99ve-been-doing-it-wrong.323822/) 

6. [Housing Policies](https://www.youtube.com/watch?v=TjKYZ5PuMAQ)

## Process

Get involved in the conversation and understanding what is under the hood
go back to the first time
teach yourself more



## Agenda

- [Let's talk about machines and automation](https://docs.google.com/presentation/d/1TEFb3xhg765oZb977kqL88mW27asBvm070WGKtI-7ic/edit?usp=sharing) (30 minutes) - Alivia
- [Algorithmic changes in the workplace](https://docs.google.com/presentation/d/12WWIX6YfzDqSLEt8SguL5qEmyF8bnlxG/edit#slide=id.p1)

[Additional reading] (https://docs.google.com/presentation/d/1dhOcoNElnAB1SkwEXdnGc4-VkWAda_yC39l8HwP-p-4/edit?usp=sharing) (30 - minutes) - Camille
- [Overview: What is Algorithmic fairness and why should you care?](https://docs.google.com/presentation/d/12WWIX6YfzDqSLEt8SguL5qEmyF8bnlxG/edit#slide=id.p1)

 [Additional Reading](https://docs.google.com/presentation/d/17Yxf31XvD8O9Prc9BhVE3H32Cgt-RMYF68Kvv4Bcbao/edit?usp=sharing) (30 minutes) - Camille
- [Organizations working in the field]() (30 minutes) - Alivia
    - [AI Now](https://ainowinstitute.org/) 
      - AI Now is a research institution based out of NYU examinging the social implications of aritificial intelligence.
      - Each year AI now holds a symposium, [2018](https://www.youtube.com/watch?v=NmdAtfcmTNg) [2017](https://www.youtube.com/watch?v=npL_UsK_npE)
      - Their reserach includes four key areas:
        - Rights and Liberties
        - Labor and Automation
        - Bias and Inclusion
        - Safety and critical infrastructure
    - [Data & Society](https://datasociety.net/about/)
      - Data & society is a research institute working out of New York City focused on the social nd cultural issues arising from data centric and automated technologies.
        - [On mapping police violence](https://www.youtube.com/watch?v=ZR64jz_eT1Q)
    - [Future of Humanity Institute](https://www.fhi.ox.ac.uk/)
      - FHI is a multidisciplinary research institute at the University of Oxford. Academics at FHI bring the tools of mathematics, philosophy, social sciences, and science to bear on big-picture questions about humanity and its prospects. The Institute is led by founding Director Professor Nick Bostrom. Humanity has the potential for a long and flourishing future. Our mission is to shed light on crucial considerations that might shape our future.
    - [MIRI - Machine Intelligence Research Institute](https://intelligence.org/about/)
      - The Machine Intelligence Research Institute is a research nonprofit studying the mathematical underpinnings of intelligent behavior. Our mission is to develop formal tools for the clean design and analysis of general-purpose AI systems, with the intent of making such systems safer and more reliable when they are developed.
    - [OpenAI](https://openai.com/charter/)
      - OpenAI’s mission is to ensure that artificial general intelligence (AGI)—by which we mean highly autonomous systems that outperform humans at most economically valuable work—benefits all of humanity. We will attempt to directly build safe and beneficial AGI, but will also consider our mission fulfilled if our work aids others to achieve this outcome.
  
- [Examination of algorithms in production and specific instances + how these have been unfair (30 minutes) - Camille](https://docs.google.com/presentation/d/1g4L9s6vz7yugt4oeGKK4-5aZeSqtLKZj/edit#slide=id.p1)
- Company efforts to mitigate bias and tools (1- hour) - What if tool - IBM Tool
- Hand- On Lab (1.5 hours)
- Stakeholders, who is responsible and for what? (1 - hour)

  how to organize product - data engineering and data science workstreams
  
  ![alt text](https://proxy.duckduckgo.com/iu/?u=http%3A%2F%2Fwww.discoverdesign.org%2Fsites%2Fdefault%2Ffiles%2Finline-images%2FCAC-Design-Process-Chart_900x867px-01.jpg&f=1)
  
  
- Data and accountability + feasibility. Who understands the data being piped into these algorithms and why do data analysts +    data scientists matter? (30 -minutes) - Alivia
- [Algorithmically enhanced machines - when hardware and software combine (30 -minutes) - Camille](https://drive.google.com/file/d/17DmuIMZXEwYJ9V-8VW9eI3j3YSDMm4k9/view?usp=sharing)

  - autonomous fleets
  - ai robots - boston dynamics
  - surgical robots - two body systems competing 
  - arbitrary AI systems
